[package]
name = "aws_lambda_events"
version = "0.6.1"
description = "AWS Lambda event definitions"
authors = [
  "Christian Legnitto <christian@legnitto.com>",
  "Sam Rijs <srijs@airpost.net>"
]
license = "MIT"
homepage = "https://github.com/LegNeato/aws-lambda-events"
repository = "https://github.com/LegNeato/aws-lambda-events"
readme = "README.md"
keywords = ["lambda", "aws", "amazon", "events", "S3"]
categories = ["api-bindings", "encoding", "web-programming"]

[badges]
travis-ci = { repository = "LegNeato/aws-lambda-events" }

[dependencies]
base64 = "0.13"
http = "0.2"
http-body = "0.4"
http-serde = "^1"
serde = "^1"
serde_derive = "^1"
serde_json = "^1"
bytes = { version = "1", features = ["serde"] }
chrono = { version = "^0.4.4", features = ["serde"] }
query_map = { version = "^0.4", features = ["serde"] }

[dev-dependencies]
pretty_assertions = "0.7"

# There are two kinds of features, `static` and `generated`.
# The `static` features reference features that we manually implement in the crate.
# The `generated` features reference features generated by the codegen script.
[features]
default = ["generated", "static"]
static = ["alb", "apigw", "cloudwatch_events", "dynamodb", "sns"]
alb = []
apigw = []
cloudwatch_events = []
dynamodb = []
sns = []

activemq = []
appsync = []
autoscaling = []
chime_bot = []
clientvpn = []
cloudwatch_logs = []
code_commit = []
codebuild = []
codedeploy = []
codepipeline = []
codepipeline_cloudwatch = []
codepipeline_job = []
cognito = []
config = []
connect = []
ecr_scan = []
firehose = []
iot = []
iot_1_click = []
iot_button = []
kafka = []
kinesis = []
kinesis_analytics = []
lex = []
rabbitmq = []
s3 = []
s3_batch_job = []
ses = []
sqs = []
streams = []
generated = ["activemq", "appsync", "autoscaling", "chime_bot", "clientvpn", "cloudwatch_logs", "code_commit", "codebuild", "codedeploy", "codepipeline_cloudwatch", "codepipeline_job", "cognito", "config", "connect", "ecr_scan", "firehose", "iot", "iot_1_click", "iot_button", "kafka", "kinesis", "kinesis_analytics", "lex", "rabbitmq", "s3", "s3_batch_job", "ses", "sqs", "streams"]
